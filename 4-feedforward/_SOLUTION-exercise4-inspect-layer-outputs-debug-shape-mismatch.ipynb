{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# [SOLUTION] Exercise 4: Debug Architectures with Shape Tracking\n",
        "\n",
        "Shape mismatches are one of the most common errors you'll encounter in deep learning. The good news? They are also one of the easiest to debug once you know how to trace tensor shapes through your network.\n",
        "\n",
        "> **Overview**: You'll encounter three broken PyTorch models that crash with shape-related errors. Using progressively sophisticated shape tracking techniques, you'll trace tensor flow, pinpoint where dimensions fail to align, and fix all three models.\n",
        "> \n",
        "> **Scenario**: The HR team's employee attrition model is evolving: adding new features, deepening the architecture, and preparing for production deployment. But each change introduces bugs. Your job is to debug all three issues using shape tracking—the most practical debugging technique in deep learning.\n",
        "> \n",
        "> **Goal**: Master the essential debugging skill of tracing tensor shapes through a network to identify and fix shape mismatch errors.\n",
        "> \n",
        "> **Tools**: Python, PyTorch, NumPy, Pandas\n",
        "> \n",
        "> **Estimated Time**: 20 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "Let's import our libraries and set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete!\n",
            "PyTorch version: 2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "# Import core libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Setup complete!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load and prepare data\n",
        "\n",
        "> Note: This step mirrors the exact same dataset and dataset processing as for [demo 4](/cd1818-intro-to-deep-learning/4-feedforward/demo4-breaking-down-forward.ipynb).\n",
        "\n",
        "We'll use the [Redsmoothy/HR_Attrition](https://huggingface.co/datasets/Redsmoothy/HR_Attrition) dataset from Hugging Face, which contains employment data for 1,470 employees.\n",
        "\n",
        "For preprocessing, we'll:\n",
        "1. Load the dataset\n",
        "2. Select 10 key numeric features\n",
        "3. Encode categorical variables\n",
        "4. Normalize features to [0, 1] range\n",
        "5. Encode the target (Attrition: Yes→1, No→0)\n",
        "6. Convert to PyTorch tensors\n",
        "\n",
        "**IMPORTANT: Feel free to skip this section to focus on the debugging task**. Just know that we end up with a dataset where each employee is represented by 10 numeric features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dataset loaded: 1470 employees found\n",
            "\n",
            "✓ Data ready: 1470 employees, 10 features each\n",
            "✓ Target shape: torch.Size([1470, 1])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Load the dataset\n",
        "dataset = load_dataset('Redsmoothy/HR_Attrition', split='train')\n",
        "print(f\"✓ Dataset loaded: {len(dataset)} employees found\\n\")\n",
        "\n",
        "# Convert to pandas\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "# 2. Select features\n",
        "feature_columns = [\n",
        "    'Age', 'DistanceFromHome', 'MonthlyIncome', 'TotalWorkingYears',\n",
        "    'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
        "    'YearsWithCurrManager', 'WorkLifeBalance', 'OverTime'\n",
        "]\n",
        "features_df = df[feature_columns].copy()\n",
        "\n",
        "# 3. Encode categorical variables\n",
        "features_df['OverTime'] = (features_df['OverTime'] == 'Yes').astype(int)\n",
        "\n",
        "# 4. Normalize features\n",
        "feature_mins = features_df.min()\n",
        "feature_maxs = features_df.max()\n",
        "features_normalized = (features_df - feature_mins) / (feature_maxs - feature_mins + 1e-8)\n",
        "\n",
        "# 5. Encode target\n",
        "target = (df['Attrition'] == 'Yes').astype(int).values\n",
        "\n",
        "# 6. Convert to tensors\n",
        "X = torch.FloatTensor(features_normalized.values)\n",
        "y = torch.FloatTensor(target).unsqueeze(1)\n",
        "\n",
        "print(f\"✓ Data ready: {X.shape[0]} employees, {X.shape[1]} features each\")\n",
        "print(f\"✓ Target shape: {y.shape}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: The three debugging challenges\n",
        "\n",
        "The HR attrition model has been through several updates, and each one introduced a different type of bug. You'll encounter three broken models that fail in different ways.\n",
        "\n",
        "**Your debugging toolkit**: You'll use progressively sophisticated shape tracking techniques to solve each challenge:\n",
        "- **Challenge 1**: Basic `print()` statements to trace shapes\n",
        "- **Challenge 2**: Build a reusable helper function for cleaner tracking\n",
        "- **Challenge 3**: Comparative tracking to reveal batch-dependent behavior\n",
        "\n",
        "Each challenge requires you to: (1) add shape tracking, (2) identify the mismatch, and (3) fix the model's `__init__`/`forward()` method.\n",
        "\n",
        "Let's dive into the challenges!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 1 - Feature expansion gone wrong\n",
        "\n",
        "The HR team wants to improve predictions by adding two new job satisfaction features to the model. The data science team updated the input layer to accept 12 features instead of 10, but something else broke in the process..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original features: torch.Size([1470, 10])\n",
            "Expanded features: torch.Size([1470, 12])\n",
            "✓ Added 2 new job satisfaction metrics\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Simulate the feature expansion by adding 2 random features\n",
        "extra_features = torch.randn(X.shape[0], 2)\n",
        "X_expanded = torch.cat([X, extra_features], dim=1)  # Now 12 features\n",
        "\n",
        "print(f\"Original features: {X.shape}\")\n",
        "print(f\"Expanded features: {X_expanded.shape}\")\n",
        "print(f\"✓ Added 2 new job satisfaction metrics\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part A: Run the model, and observe the error\n",
        "\n",
        "Let's try to run the model and see what error we get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model with expanded input:\n",
            "BrokenExpandedMLP(\n",
            "  (layer1): Linear(in_features=12, out_features=20, bias=True)\n",
            "  (layer2): Linear(in_features=10, out_features=5, bias=True)\n",
            "  (layer3): Linear(in_features=5, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "class BrokenExpandedMLP(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(BrokenExpandedMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(12, 20)\n",
        "        self.layer2 = nn.Linear(10, 5)\n",
        "        self.layer3 = nn.Linear(5, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "broken_model = BrokenExpandedMLP()\n",
        "print(\"Model with expanded input:\")\n",
        "print(broken_model)\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([5, 12])\n",
            "\n",
            "Attempting forward pass...\n",
            "\n",
            "✖ RuntimeError occurred!\n",
            "\n",
            "Error message: mat1 and mat2 shapes cannot be multiplied (5x20 and 10x5)\n"
          ]
        }
      ],
      "source": [
        "# Try to run the model\n",
        "sample_batch = X_expanded[:5]\n",
        "\n",
        "print(f\"Input shape: {sample_batch.shape}\")\n",
        "print(\"\\nAttempting forward pass...\\n\")\n",
        "\n",
        "try:\n",
        "    output = broken_model(sample_batch)\n",
        "    print(f\"✓ Success! Output shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"✖ RuntimeError occurred!\")\n",
        "    print(f\"\\nError message: {e}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Understanding the error**: The error mentions matrix multiplication failure, but doesn't clearly indicate which layer or why. Time to add shape tracking."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part B: Add tensor shape tracking, and run again to debug\n",
        "\n",
        "Add `print()` statements to track tensor shapes at each step of the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model with shape tracking created!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class BrokenAttritionMLPWithTracking(nn.Module):\n",
        "    \"\"\"\n",
        "    Same broken model, but with shape tracking to debug the issue.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(BrokenAttritionMLPWithTracking, self).__init__()\n",
        "        self.layer1 = nn.Linear(12, 20)\n",
        "        self.layer2 = nn.Linear(10, 5)\n",
        "        self.layer3 = nn.Linear(5, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # TODO: Add print statements to track shapes\n",
        "        # Hint: Use print(f\"{Description}: {shape}\") at strategic points\n",
        "        # The description should describe what stage the tensor is at when you print its shape\n",
        "        # Reference: https://docs.pytorch.org/docs/stable/generated/torch.Tensor.shape.html\n",
        "\n",
        "        # SOLUTION: Add print statements at each step\n",
        "        print(f\"Input: {x.shape}\")\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        print(f\"After layer1: {x.shape}\")\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        print(f\"After ReLU: {x.shape}\")\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        print(f\"After layer2: {x.shape}\")  # Won't print - crashes here!\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        print(f\"After ReLU: {x.shape}\")\n",
        "        \n",
        "        x = self.layer3(x)\n",
        "        print(f\"After layer3: {x.shape}\")\n",
        "        \n",
        "        x = torch.sigmoid(x)\n",
        "        print(f\"After sigmoid: {x.shape}\")\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "# Instantiate model with tracking\n",
        "tracked_model = BrokenAttritionMLPWithTracking()\n",
        "print(\"Model with shape tracking created!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running forward pass WITH shape tracking:\n",
            "\n",
            "============================================================\n",
            "Input: torch.Size([5, 12])\n",
            "After layer1: torch.Size([5, 20])\n",
            "After ReLU: torch.Size([5, 20])\n",
            "============================================================\n",
            "\n",
            "✖ Error still occurs, but now we can see exactly WHERE!\n",
            "\n",
            "Error: mat1 and mat2 shapes cannot be multiplied (5x20 and 10x5)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run with tracking\n",
        "print(\"Running forward pass WITH shape tracking:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    output = tracked_model(sample_batch)\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\n✓ Success! Output: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✖ Error still occurs, but now we can see exactly WHERE!\")\n",
        "    print(f\"\\nError: {e}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reading the tracking output**: Notice where the print statements stop. The last shape that successfully printed tells you exactly where the error occurs. Compare that shape to what the next layer expects (you can see this in the `__init__` method or in the error message's matrix dimensions)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part C: Fix the model, and run again\n",
        "\n",
        "Time to define the corrected model with properly aligned dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed model created!\n",
            "\n",
            "FixedExpandedMLP(\n",
            "  (layer1): Linear(in_features=12, out_features=20, bias=True)\n",
            "  (layer2): Linear(in_features=20, out_features=5, bias=True)\n",
            "  (layer3): Linear(in_features=5, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class FixedExpandedMLP(nn.Module):\n",
        "    # TODO: Define the correct model with fixed dimensions\n",
        "    # Hint: You can copy-paste from BrokenAttritionMLPWithTracking, changing only what's needed\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(FixedExpandedMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(12, 20)\n",
        "        self.layer2 = nn.Linear(20, 5)   # SOLUTION: Changed from 10 to 20\n",
        "        self.layer3 = nn.Linear(5, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Keep tracking to verify the fix\n",
        "        print(f\"Input: {x.shape}\")\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        print(f\"After layer1: {x.shape}\")\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        print(f\"After ReLU: {x.shape}\")\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        print(f\"After layer2: {x.shape}\")\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        x = self.layer3(x)\n",
        "        print(f\"After layer3: {x.shape}\")\n",
        "        \n",
        "        x = torch.sigmoid(x)\n",
        "        print(f\"Final output: {x.shape}\")\n",
        "        \n",
        "        return x\n",
        "\n",
        "fixed_model_1 = FixedExpandedMLP()\n",
        "print(\"Fixed model created!\\n\")\n",
        "print(fixed_model_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing the fixed model:\n",
            "\n",
            "============================================================\n",
            "Input: torch.Size([5, 12])\n",
            "After layer1: torch.Size([5, 20])\n",
            "After ReLU: torch.Size([5, 20])\n",
            "After layer2: torch.Size([5, 5])\n",
            "After layer3: torch.Size([5, 1])\n",
            "Final output: torch.Size([5, 1])\n",
            "============================================================\n",
            "\n",
            "✓ SUCCESS! The model runs without errors.\n",
            "\n",
            "Output shape: torch.Size([5, 1])\n"
          ]
        }
      ],
      "source": [
        "# Test the fixed model\n",
        "print(\"Testing the fixed model:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    output = fixed_model_1(sample_batch)\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✓ SUCCESS! The model runs without errors.\")\n",
        "    print(f\"\\nOutput shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✖ Still broken. Review your fix and try again.\")\n",
        "    print(f\"\\nError: {e}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Verification success**: The shapes should now flow smoothly through every layer. Each transformation produces exactly what the next layer expects, and the model processes all 5 employees in parallel without issues."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TODO: Analysis question\n",
        "\n",
        "**Question:** Based on the shape tracking you added, explain why activation functions like ReLU don't cause shape mismatches, while Linear layers can. What's fundamentally different about how these two types of operations work?\n",
        "\n",
        "_Write your answer here:_\n",
        "\n",
        "Activation functions like ReLU apply **element-wise transformations**—they process each value independently without changing the tensor's structure, so a `(5, 20)` tensor stays `(5, 20)` after ReLU. Linear layers, in contrast, perform **matrix multiplications** that transform the feature dimension: they map `n` input features to `m` output features, changing the shape from `(batch, n)` to `(batch, m)`. This transformation requires strict dimensional alignment—if layer1 outputs 30 features but layer2 expects 20, the matrix multiplication mathematically cannot proceed, resulting in a shape mismatch error."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2: Deeper network, new problems\n",
        "\n",
        "To capture more complex patterns in attrition risk, the team decided to add an extra hidden layer, creating a deeper 4-layer architecture. The model compiles but crashes during the forward pass..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use original 10-feature dataset for this challenge\n",
        "sample_batch = X[:5]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part A: Run the model, and observe the error\n",
        "\n",
        "Let's try to run the model and see what error we get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deeper model created:\n",
            "BrokenDeeperMLP(\n",
            "  (layer1): Linear(in_features=10, out_features=30, bias=True)\n",
            "  (layer2): Linear(in_features=30, out_features=15, bias=True)\n",
            "  (layer3): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (layer4): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "class BrokenDeeperMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BrokenDeeperMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 30)\n",
        "        self.layer2 = nn.Linear(30, 15)\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "        self.layer4 = nn.Linear(10, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer4(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "broken_deeper = BrokenDeeperMLP()\n",
        "print(\"Deeper model created:\")\n",
        "print(broken_deeper)\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([5, 10])\n",
            "\n",
            "Attempting forward pass...\n",
            "\n",
            "✖ RuntimeError occurred!\n",
            "\n",
            "Error message: mat1 and mat2 shapes cannot be multiplied (5x15 and 20x10)\n"
          ]
        }
      ],
      "source": [
        "# Try to run the model\n",
        "print(f\"Input shape: {sample_batch.shape}\")\n",
        "print(\"\\nAttempting forward pass...\\n\")\n",
        "\n",
        "try:\n",
        "    output = broken_deeper(sample_batch)\n",
        "    print(f\"✓ Success! Output shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"✖ RuntimeError occurred!\")\n",
        "    print(f\"\\nError message: {e}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **More layers, more places to break**: In deeper networks, simple print statements can become cluttered. Time to build a reusable debugging tool."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part B: Add tensor shape tracking, and run again to debug\n",
        "\n",
        "Instead of plain `print()` statements, build a reusable helper function that formats shape information clearly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing the helper function:\n",
            "============================================================\n",
            "Test input                     → torch.Size([5, 10]) \n",
            "============================================================\n",
            "\n",
            "✓ Helper function ready!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO: Create a helper function for formatted shape tracking\n",
        "# Hint: Use f-strings to format output as: \"name → shape\"\n",
        "# Format the name field to be 30 characters wide and shape to be 20 characters.\n",
        "# Reference: https://docs.python.org/3/tutorial/inputoutput.html#formatted-string-literals\n",
        "\n",
        "def print_shape_with_arrow(name, tensor):\n",
        "    \"\"\"\n",
        "    Helper function to print tensor shapes in a clean, readable format.\n",
        "    \n",
        "    Args:\n",
        "        name: Description of the operation/layer\n",
        "        tensor: The tensor whose shape we want to display\n",
        "    \"\"\"\n",
        "    # Add your code here\n",
        "    print(f\"{name:30s} → {str(tensor.shape):20s}\")\n",
        "\n",
        "# Test the helper function\n",
        "test_tensor = torch.randn(5, 10)\n",
        "print(\"\\nTesting the helper function:\")\n",
        "print(\"=\"*60)\n",
        "print_shape_with_arrow(\"Test input\", test_tensor)\n",
        "print(\"=\"*60)\n",
        "print(\"\\n✓ Helper function ready!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model with enhanced tracking created!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class BrokenDeeperMLPWithTracking(nn.Module):\n",
        "    \"\"\"\n",
        "    Same broken model, now using the helper function for tracking.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(BrokenDeeperMLPWithTracking, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 30)\n",
        "        self.layer2 = nn.Linear(30, 15)\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "        self.layer4 = nn.Linear(10, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # TODO: Use your helper function to track shapes at each step\n",
        "        # Hint: Call print_shape_with_arrow(description, tensor) throughout\n",
        "        \n",
        "        print_shape_with_arrow(\"Input\", x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        print_shape_with_arrow(\"After layer1 (Linear 10→30)\", x)\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        print_shape_with_arrow(\"After ReLU\", x)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        print_shape_with_arrow(\"After layer2 (Linear 30→15)\", x)\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        print_shape_with_arrow(\"After ReLU\", x)\n",
        "        \n",
        "        print_shape_with_arrow(\"Before layer3 (expects 20)\", x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        x = self.layer4(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "tracked_deeper = BrokenDeeperMLPWithTracking()\n",
        "print(\"Model with enhanced tracking created!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running forward pass with FORMATTED shape tracking:\n",
            "\n",
            "============================================================\n",
            "Input                          → torch.Size([5, 10]) \n",
            "After layer1 (Linear 10→30)    → torch.Size([5, 30]) \n",
            "After ReLU                     → torch.Size([5, 30]) \n",
            "After layer2 (Linear 30→15)    → torch.Size([5, 15]) \n",
            "After ReLU                     → torch.Size([5, 15]) \n",
            "Before layer3 (expects 20)     → torch.Size([5, 15]) \n",
            "============================================================\n",
            "\n",
            "Error: mat1 and mat2 shapes cannot be multiplied (5x15 and 20x10)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run with enhanced tracking\n",
        "print(\"Running forward pass with FORMATTED shape tracking:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    output = tracked_deeper(sample_batch)\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\n✓ Success! Output: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nError: {e}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reading the formatted output**: The helper function makes it easy to scan through the shape flow. Notice where the prints stop - that's your clue. Check the unprinted layer's definition in `__init__` to identify the mismatch.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part C: Fix the model, and run again\n",
        "\n",
        "Time to define the corrected model with properly aligned dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed deeper model created!\n",
            "\n",
            "FixedDeeperMLP(\n",
            "  (layer1): Linear(in_features=10, out_features=30, bias=True)\n",
            "  (layer2): Linear(in_features=30, out_features=15, bias=True)\n",
            "  (layer3): Linear(in_features=15, out_features=10, bias=True)\n",
            "  (layer4): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class FixedDeeperMLP(nn.Module):\n",
        "    # TODO: Define the correct model with fixed dimensions\n",
        "    # Hint: You can copy-paste from BrokenDeeperMLPWithTracking, changing only what's needed\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(FixedDeeperMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 30)\n",
        "        self.layer2 = nn.Linear(30, 15)\n",
        "        self.layer3 = nn.Linear(15, 10)  # SOLUTION: Changed from 20 to 15\n",
        "        self.layer4 = nn.Linear(10, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Keep tracking to verify\n",
        "        print_shape_with_arrow(\"Input\", x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        print_shape_with_arrow(\"After layer1\", x)\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        print_shape_with_arrow(\"After layer2\", x)\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = self.layer3(x)\n",
        "        print_shape_with_arrow(\"After layer3\", x)\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = self.layer4(x)\n",
        "        print_shape_with_arrow(\"After layer4\", x)\n",
        "        \n",
        "        x = torch.sigmoid(x)\n",
        "        print_shape_with_arrow(\"Final output\", x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "fixed_model_2 = FixedDeeperMLP()\n",
        "print(\"Fixed deeper model created!\\n\")\n",
        "print(fixed_model_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing the fixed deeper model:\n",
            "\n",
            "============================================================\n",
            "Input                          → torch.Size([5, 10]) \n",
            "After layer1                   → torch.Size([5, 30]) \n",
            "After layer2                   → torch.Size([5, 15]) \n",
            "After layer3                   → torch.Size([5, 10]) \n",
            "After layer4                   → torch.Size([5, 1])  \n",
            "Final output                   → torch.Size([5, 1])  \n",
            "============================================================\n",
            "\n",
            "✓ SUCCESS! The deeper model now runs without errors.\n",
            "\n",
            "Output shape: torch.Size([5, 1])\n"
          ]
        }
      ],
      "source": [
        "# Test the fixed model\n",
        "print(\"Testing the fixed deeper model:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    output = fixed_model_2(sample_batch)\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✓ SUCCESS! The deeper model now runs without errors.\")\n",
        "    print(f\"\\nOutput shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✖ Still broken. Review the layer dimensions.\")\n",
        "    print(f\"\\nError: {e}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Verification success**: The dimension chain should now be consistent: `10 → 30 → 15 → 10 → 1`. Your helper function made debugging and identifying the right fix much cleaner than manual inspection."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TODO: Analysis question\n",
        "\n",
        "**Question:** The error message said \"mat1 and mat2 shapes cannot be multiplied (5x15 and 20x10)\". You could technically figure out the broken layer by examining the `__init__()` method and mentally tracing which layer outputs 15 features and which expects 20. Why is adding shape tracking still more efficient than this mental tracing approach, especially as networks get deeper?\n",
        "\n",
        "_Write your answer here:_\n",
        "\n",
        "**Example Answer:** Mental tracing requires you to work backwards from the error (15 → 20 mismatch), examine every layer definition in `__init__`, and deduce the sequence; this is a process prone to mistakes in networks with 5+ layers. Shape tracking shows you the exact execution order with real tensor shapes at each step, eliminating guesswork and making the bug immediately visible. As networks grow deeper with branches, skip connections, or conditional paths, mental tracing becomes impractical while shape tracking remains straightforward."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3: The batch size 1 mystery\n",
        "\n",
        "The model has been updated with normalization to improve convergence. It passes all training tests (batch size 32), but crashes in production when processing single employees. This is a subtle bug that only appears with certain batch sizes..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use original 10-feature dataset for this challenge\n",
        "sample_batch = X[:32]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part A: Run the model, and observe the error\n",
        "\n",
        "Let's try to run the model and see what error we get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch-dependent model created:\n",
            "BrokenBatchDependentMLP(\n",
            "  (layer1): Linear(in_features=10, out_features=20, bias=True)\n",
            "  (layer2): Linear(in_features=20, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "class BrokenBatchDependentMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BrokenBatchDependentMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 20)\n",
        "        self.layer2 = nn.Linear(20, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = x.reshape(32, 1, -1)  # (batch, 20) → (batch, 1, 20)\n",
        "        x = x.mean(dim=1)  # Average across dim 1: (batch, 1, 20) → (batch, 20)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "broken_batch = BrokenBatchDependentMLP()\n",
        "print(\"Batch-dependent model created:\")\n",
        "print(broken_batch)\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with training batch size:\n",
            "✓ Works! Output shape: torch.Size([32, 1])\n",
            "\n",
            "Testing with batch size 1 (production):\n",
            "✖ Error: shape '[32, 1, -1]' is invalid for input of size 20\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Test with batch size 32 (training scenario)\n",
        "print(\"Testing with training batch size:\")\n",
        "\n",
        "try:\n",
        "    output = broken_batch(sample_batch)\n",
        "    print(f\"✓ Works! Output shape: {output.shape}\\n\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"✖ Error: {e}\\n\")\n",
        "\n",
        "# Test with batch size 1 (production scenario)\n",
        "print(\"Testing with batch size 1 (production):\")\n",
        "batch_1 = X[:1]\n",
        "\n",
        "try:\n",
        "    output = broken_batch(batch_1)\n",
        "    print(f\"✓ Works! Output shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"✖ Error: {e}\")\n",
        "    print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Batch-dependent behavior**: The model's behavior changes based on input size. This suggests an operation that treats dimensions differently depending on their values."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part B: Add tensor shape tracking, and run again to debug\n",
        "\n",
        "Run both batch sizes and compare outputs side-by-side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrokenBatchDependentMLPWithTracking(nn.Module):\n",
        "    \"\"\"\n",
        "    Same broken model with comparative tracking.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(BrokenBatchDependentMLPWithTracking, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 20)\n",
        "        self.layer2 = nn.Linear(20, 1)\n",
        "    \n",
        "    def forward(self, x, batch_label=\"\"):\n",
        "        # TODO: Add comparative tracking focused on the batch size\n",
        "        # Hint: Include the `batch_label` parameter in your print\n",
        "        # This lets you run the same model with different batch sizes and compare outputs side-by-side.\n",
        "        \n",
        "        print(f\"  [{batch_label}] Input: {x.shape}\")\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        print(f\"  [{batch_label}] After layer1: {x.shape}\")\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        print(f\"  [{batch_label}] After ReLU: {x.shape}\")\n",
        "        \n",
        "        print(f\"  [{batch_label}] Before reshape(32, 1, -1): {x.shape}\")\n",
        "        x = x.reshape(32, 1, -1)\n",
        "        print(f\"  [{batch_label}] After reshape: {x.shape}\")\n",
        "        \n",
        "        x = x.mean(dim=1)\n",
        "        print(f\"  [{batch_label}] After mean: {x.shape}\")\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "tracked_batch = BrokenBatchDependentMLPWithTracking()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparative shape tracking:\n",
            "\n",
            "============================================================\n",
            "\n",
            "Batch size 32:\n",
            "----------------------------------------\n",
            "  [] Input: torch.Size([32, 10])\n",
            "  [] After layer1: torch.Size([32, 20])\n",
            "  [] After ReLU: torch.Size([32, 20])\n",
            "  [] Before reshape(32, 1, -1): torch.Size([32, 20])\n",
            "  [] After reshape: torch.Size([32, 1, 20])\n",
            "  [] After mean: torch.Size([32, 20])\n",
            "  ✓ Success! Output: torch.Size([32, 1])\n",
            "\n",
            "Batch size 1:\n",
            "----------------------------------------\n",
            "  [] Input: torch.Size([1, 10])\n",
            "  [] After layer1: torch.Size([1, 20])\n",
            "  [] After ReLU: torch.Size([1, 20])\n",
            "  [] Before reshape(32, 1, -1): torch.Size([1, 20])\n",
            "  ✖ Error: shape '[32, 1, -1]' is invalid for input of size 20\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Run both batch sizes with tracking\n",
        "print(\"Comparative shape tracking:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nBatch size 32:\")\n",
        "print(\"-\" * 40)\n",
        "try:\n",
        "    output = tracked_batch(sample_batch)\n",
        "    print(f\"  ✓ Success! Output: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"  ✖ Error: {e}\")\n",
        "\n",
        "print(\"\\nBatch size 1:\")\n",
        "print(\"-\" * 40)\n",
        "try:\n",
        "    output = tracked_batch(batch_1)\n",
        "    print(f\"  ✓ Success! Output: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"  ✖ Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reading the comparative output**: Execution stops at the reshape operation when Batch=1. The error message shows `[32, 1, -1]`. Notice an unexpected `32` appearing in the reshape - does that number make sense for a batch of size 1?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part C: Fix the model, and run again\n",
        "\n",
        "Time to define the corrected model with properly aligned dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed batch-independent model created!\n",
            "\n",
            "FixedBatchDependentMLP(\n",
            "  (layer1): Linear(in_features=10, out_features=20, bias=True)\n",
            "  (layer2): Linear(in_features=20, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class FixedBatchDependentMLP(nn.Module):\n",
        "    # TODO: Define the correct model with fixed dimensions\n",
        "    # Hint: You can copy-paste from BatchDependentMLPWithTracking, changing only what's needed\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(FixedBatchDependentMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 20)\n",
        "        self.layer2 = nn.Linear(20, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        print(f\"  Input: {x.shape}\")\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        print(f\"  After layer1: {x.shape}\")\n",
        "        \n",
        "        x = torch.relu(x)\n",
        "        print(f\"  After ReLU: {x.shape}\")\n",
        "        \n",
        "        # SOLUTION: Use -1 or x.shape[0] to make it dynamic\n",
        "        batch_size = x.shape[0]\n",
        "        x = x.reshape(batch_size, 1, -1)  # Dynamic: (batch, 20) → (batch, 1, 20)\n",
        "        print(f\"  After reshape: {x.shape}\")\n",
        "        \n",
        "        x = x.mean(dim=1)\n",
        "        print(f\"  After mean: {x.shape}\")\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        print(f\"  After layer2: {x.shape}\")\n",
        "        \n",
        "        x = torch.sigmoid(x)\n",
        "        print(f\"  Final output: {x.shape}\")\n",
        "        \n",
        "        return x\n",
        "\n",
        "fixed_model_3 = FixedBatchDependentMLP()\n",
        "print(\"Fixed batch-independent model created!\\n\")\n",
        "print(fixed_model_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing fixed model with different batch sizes:\n",
            "\n",
            "============================================================\n",
            "\n",
            "Batch size: 1\n",
            "----------------------------------------\n",
            "  Input: torch.Size([1, 10])\n",
            "  After layer1: torch.Size([1, 20])\n",
            "  After ReLU: torch.Size([1, 20])\n",
            "  After reshape: torch.Size([1, 1, 20])\n",
            "  After mean: torch.Size([1, 20])\n",
            "  After layer2: torch.Size([1, 1])\n",
            "  Final output: torch.Size([1, 1])\n",
            "  ✓ Success! Consistent output shape: torch.Size([1, 1])\n",
            "\n",
            "Batch size: 5\n",
            "----------------------------------------\n",
            "  Input: torch.Size([5, 10])\n",
            "  After layer1: torch.Size([5, 20])\n",
            "  After ReLU: torch.Size([5, 20])\n",
            "  After reshape: torch.Size([5, 1, 20])\n",
            "  After mean: torch.Size([5, 20])\n",
            "  After layer2: torch.Size([5, 1])\n",
            "  Final output: torch.Size([5, 1])\n",
            "  ✓ Success! Consistent output shape: torch.Size([5, 1])\n",
            "\n",
            "Batch size: 32\n",
            "----------------------------------------\n",
            "  Input: torch.Size([32, 10])\n",
            "  After layer1: torch.Size([32, 20])\n",
            "  After ReLU: torch.Size([32, 20])\n",
            "  After reshape: torch.Size([32, 1, 20])\n",
            "  After mean: torch.Size([32, 20])\n",
            "  After layer2: torch.Size([32, 1])\n",
            "  Final output: torch.Size([32, 1])\n",
            "  ✓ Success! Consistent output shape: torch.Size([32, 1])\n",
            "\n",
            "============================================================\n",
            "\n",
            "✓ Model works correctly with all batch sizes!\n"
          ]
        }
      ],
      "source": [
        "# Test with multiple batch sizes\n",
        "print(\"Testing fixed model with different batch sizes:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for batch_size in [1, 5, 32]:\n",
        "    batch = X[:batch_size]\n",
        "    print(f\"\\nBatch size: {batch_size}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    try:\n",
        "        output = fixed_model_3(batch)\n",
        "        print(f\"  ✓ Success! Consistent output shape: {output.shape}\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"  ✖ Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\n✓ Model works correctly with all batch sizes!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TODO: Analysis question\n",
        "\n",
        "**Question:** Why is hardcoding values like batch size a dangerous habit in neural networks? Beyond `reshape()`, what other PyTorch operations might behave unexpectedly when dimensions are hardcoded or when certain dimensions equal 1?\n",
        "\n",
        "_Write your answer here:_\n",
        "\n",
        "**Example Answer:** Hardcoding batch sizes creates brittle code that only works under specific conditions, breaking when batch sizes change between training (e.g., 32), validation (e.g., 64), or production inference (often 1). The correct pattern is dynamic reshaping using `x.shape[0]` or `-1`: `x.reshape(x.shape[0], 1, -1)` or `x.reshape(-1, 1, 20)`. Beyond reshape, operations like `squeeze()` without arguments remove ALL size-1 dimensions, so with batch=1, a tensor `(1, 20)` becomes `(20)`, accidentally removing the batch dimension entirely. Similarly, `BatchNorm1d` requires batch size > 1 to compute meaningful statistics, and operations like `mean(dim=0)` collapse the batch dimension, which might not be intended for single-example inference."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Test with different batch sizes\n",
        "\n",
        "A robust model should handle any batch size gracefully. Let's verify all three fixed models work across different scenarios, from single predictions to large batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comprehensive batch size testing across all three models:\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Model 1: Feature Expansion (12 features → 1 output)\n",
            "----------------------------------------------------------------------\n",
            "  Batch=  1 → Input: torch.Size([1, 12]) → Output: torch.Size([1, 1]) ✓\n",
            "  Batch=  5 → Input: torch.Size([5, 12]) → Output: torch.Size([5, 1]) ✓\n",
            "  Batch= 32 → Input: torch.Size([32, 12]) → Output: torch.Size([32, 1]) ✓\n",
            "  Batch=128 → Input: torch.Size([128, 12]) → Output: torch.Size([128, 1]) ✓\n",
            "\n",
            "Model 2: Deeper Network (10 → 30 → 15 → 10 → 1)\n",
            "----------------------------------------------------------------------\n",
            "  Batch=  1 → Input: torch.Size([1, 10]) → Output: torch.Size([1, 1]) ✓\n",
            "  Batch=  5 → Input: torch.Size([5, 10]) → Output: torch.Size([5, 1]) ✓\n",
            "  Batch= 32 → Input: torch.Size([32, 10]) → Output: torch.Size([32, 1]) ✓\n",
            "  Batch=128 → Input: torch.Size([128, 10]) → Output: torch.Size([128, 1]) ✓\n",
            "\n",
            "Model 3: Batch-Independent (no squeeze issues)\n",
            "----------------------------------------------------------------------\n",
            "  Batch=  1 → Input: torch.Size([1, 10]) → Output: torch.Size([1, 1]) ✓\n",
            "  Batch=  5 → Input: torch.Size([5, 10]) → Output: torch.Size([5, 1]) ✓\n",
            "  Batch= 32 → Input: torch.Size([32, 10]) → Output: torch.Size([32, 1]) ✓\n",
            "  Batch=128 → Input: torch.Size([128, 10]) → Output: torch.Size([128, 1]) ✓\n",
            "\n",
            "======================================================================\n",
            "\n",
            "✓ All three models work correctly across all batch sizes!\n"
          ]
        }
      ],
      "source": [
        "# Test all three fixed models comprehensively\n",
        "test_batch_sizes = [1, 5, 32, 128]\n",
        "\n",
        "print(\"Comprehensive batch size testing across all three models:\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Model 1: Feature expansion fix\n",
        "print(\"\\nModel 1: Feature Expansion (12 features → 1 output)\")\n",
        "print(\"-\" * 70)\n",
        "for batch_size in test_batch_sizes:\n",
        "    batch = X_expanded[:batch_size]\n",
        "    \n",
        "    with torch.no_grad():  # No gradients needed for testing\n",
        "        # Run without printing intermediate shapes\n",
        "        output = fixed_model_1.layer3(torch.relu(fixed_model_1.layer2(\n",
        "                 torch.relu(fixed_model_1.layer1(batch)))))\n",
        "        output = torch.sigmoid(output)\n",
        "    \n",
        "    print(f\"  Batch={batch_size:3d} → Input: {str(batch.shape):15s} → Output: {str(output.shape):15s} ✓\")\n",
        "\n",
        "# Model 2: Deeper network fix\n",
        "print(\"\\nModel 2: Deeper Network (10 → 30 → 15 → 10 → 1)\")\n",
        "print(\"-\" * 70)\n",
        "for batch_size in test_batch_sizes:\n",
        "    batch = X[:batch_size]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = fixed_model_2.layer4(torch.relu(fixed_model_2.layer3(\n",
        "                 torch.relu(fixed_model_2.layer2(torch.relu(\n",
        "                 fixed_model_2.layer1(batch)))))))\n",
        "        output = torch.sigmoid(output)\n",
        "    \n",
        "    print(f\"  Batch={batch_size:3d} → Input: {str(batch.shape):15s} → Output: {str(output.shape):15s} ✓\")\n",
        "\n",
        "# Model 3: Batch-dependent bug fix\n",
        "print(\"\\nModel 3: Batch-Independent (no fixed dimensions)\")\n",
        "print(\"-\" * 70)\n",
        "for batch_size in test_batch_sizes:\n",
        "    batch = X[:batch_size]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = fixed_model_3.layer2(torch.relu(fixed_model_3.layer1(batch)))\n",
        "        output = torch.sigmoid(output)\n",
        "    \n",
        "    print(f\"  Batch={batch_size:3d} → Input: {str(batch.shape):15s} → Output: {str(output.shape):15s} ✓\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\\n✓ All three models work correctly across all batch sizes!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Production-ready models are batch-agnostic**: All three fixed models now produce consistent output patterns: `(batch, 1)`. The first dimension scales with input, the second stays constant. Testing across [1, 5, 32, 128] confirms there are no hidden batch-dependent bugs. This robustness—working correctly whether processing one example or hundreds—is essential for real-world deployment where batch sizes vary unpredictably."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TODO: Analysis question\n",
        "\n",
        "**Question:** Based on your experience debugging all three models, why is testing with batch size 1 especially important? What kinds of bugs only appear at this edge case?\n",
        "\n",
        "_Write your answer here:_\n",
        "\n",
        "Testing with batch size 1 catches **data-dependent bugs** that behave differently when dimensions equal 1. Operations like `squeeze()` remove all size-1 dimensions, so with batch=1, they accidentally remove the batch dimension itself, changing a 2D tensor `(1, features)` to 1D `(features)`. This breaks layers expecting 2D inputs, but the bug is invisible with larger batches where no dimensions equal 1. Batch size 1 also tests edge cases in operations like batch normalization (can't normalize a single sample) and certain attention mechanisms, making it a critical test case for production-ready models that may process single examples."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations! You've successfully debugged three different types of shape-related errors using progressively sophisticated tracking techniques.\n",
        "\n",
        "**What you've accomplished:**\n",
        "\n",
        "- [x] **Debugged a feature expansion mismatch** - Fixed incompatible layer sizes after adding new input features\n",
        "- [x] **Debugged a deeper network** - Identified misaligned dimensions in a 4-layer architecture\n",
        "- [x] **Debugged a batch-dependent operation** - Fixed a hardcoded reshape that only worked with one fixed batch size value\n",
        "- [x] **Built reusable debugging tools** - Created helper functions for cleaner shape tracking\n",
        "- [x] **Verified robustness** - Tested all fixes across multiple batch sizes (1, 5, 32, 128)\n",
        "\n",
        "**Critical insights:**\n",
        "\n",
        "- **Shape tracking is your primary debugging tool**: Whether simple prints or helper functions, inspecting shapes reveals exactly where dimensions fail to align\n",
        "- **Linear layers transform dimensions**: Matrix multiplication changes feature counts and requires strict alignment between consecutive layers\n",
        "- **Activation functions preserve dimensions**: Element-wise operations like ReLU never cause shape mismatches\n",
        "- **Some operations are batch-dependent**: Hardcoded dimensions in operations like `reshape()` create bugs that only manifest with specific batch sizes\n",
        "- **Batch size 1 is the critical edge case**: Many bugs only manifest when the batch dimension equals 1, making it essential for testing\n",
        "- **Progressive debugging techniques**: Start simple (basic prints), then build tools (helper functions), then analyze systematically (comparative tracking)\n",
        "\n",
        "Shape mismatch errors aren't mysteries: they're clear signals pointing to architectural inconsistencies. By adding targeted shape tracking (instead of logging everything), you turn opaque runtime failures into clear debugging steps, saving hours when building custom architectures or adapting models. When something breaks, you now know exactly how to trace and fix it.\n",
        "\n",
        "> **Next steps to explore**: Print statements work for models you can edit, but for pre-trained or cleaner workflows, PyTorch’s hooks, decorators, and context managers let you log shapes non-invasively—ideal for scaling from development to production."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "36371cb60c26e37b7d9a2ceed614c6abe3cd2e9c2c4d621fd25f98fd923082ac"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
