{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 4: Debug Architectures with Shape Tracking\n",
        "\n",
        "Shape mismatches are one of the most common errors you'll encounter in deep learning. The good news? They are also one of the easiest to debug once you know how to trace tensor shapes through your network.\n",
        "\n",
        "> **Overview**: You'll encounter three broken PyTorch models that crash with shape-related errors. Using progressively sophisticated shape tracking techniques, you'll trace tensor flow, pinpoint where dimensions fail to align, and fix all three models.\n",
        "> \n",
        "> **Scenario**: The HR team's employee attrition model is evolving: adding new features, deepening the architecture, and preparing for production deployment. But each change introduces bugs. Your job is to debug all three issues using shape tracking—the most practical debugging technique in deep learning.\n",
        "> \n",
        "> **Goal**: Master the essential debugging skill of tracing tensor shapes through a network to identify and fix shape mismatch errors.\n",
        "> \n",
        "> **Tools**: Python, PyTorch, NumPy, Pandas\n",
        "> \n",
        "> **Estimated Time**: 20 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "Let's import our libraries and set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import core libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Setup complete!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load and prepare data\n",
        "\n",
        "> Note: This step mirrors the exact same dataset and dataset processing as for [demo 4](/cd1818-intro-to-deep-learning/4-feedforward/demo4-breaking-down-forward.ipynb).\n",
        "\n",
        "We'll use the [Redsmoothy/HR_Attrition](https://huggingface.co/datasets/Redsmoothy/HR_Attrition) dataset from Hugging Face, which contains employment data for 1,470 employees.\n",
        "\n",
        "For preprocessing, we'll:\n",
        "1. Load the dataset\n",
        "2. Select 10 key numeric features\n",
        "3. Encode categorical variables\n",
        "4. Normalize features to [0, 1] range\n",
        "5. Encode the target (Attrition: Yes→1, No→0)\n",
        "6. Convert to PyTorch tensors\n",
        "\n",
        "**IMPORTANT: Feel free to skip this section to focus on the debugging task**. Just know that we end up with a dataset where each employee is represented by 10 numeric features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Load the dataset\n",
        "dataset = load_dataset('Redsmoothy/HR_Attrition', split='train')\n",
        "print(f\"✓ Dataset loaded: {len(dataset)} employees found\\n\")\n",
        "\n",
        "# Convert to pandas\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "# 2. Select features\n",
        "feature_columns = [\n",
        "    'Age', 'DistanceFromHome', 'MonthlyIncome', 'TotalWorkingYears',\n",
        "    'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
        "    'YearsWithCurrManager', 'WorkLifeBalance', 'OverTime'\n",
        "]\n",
        "features_df = df[feature_columns].copy()\n",
        "\n",
        "# 3. Encode categorical variables\n",
        "features_df['OverTime'] = (features_df['OverTime'] == 'Yes').astype(int)\n",
        "\n",
        "# 4. Normalize features\n",
        "feature_mins = features_df.min()\n",
        "feature_maxs = features_df.max()\n",
        "features_normalized = (features_df - feature_mins) / (feature_maxs - feature_mins + 1e-8)\n",
        "\n",
        "# 5. Encode target\n",
        "target = (df['Attrition'] == 'Yes').astype(int).values\n",
        "\n",
        "# 6. Convert to tensors\n",
        "X = torch.FloatTensor(features_normalized.values)\n",
        "y = torch.FloatTensor(target).unsqueeze(1)\n",
        "\n",
        "print(f\"✓ Data ready: {X.shape[0]} employees, {X.shape[1]} features each\")\n",
        "print(f\"✓ Target shape: {y.shape}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: The three debugging challenges\n",
        "\n",
        "The HR attrition model has been through several updates, and each one introduced a different type of bug. You'll encounter three broken models that fail in different ways.\n",
        "\n",
        "**Your debugging toolkit**: You'll use progressively sophisticated shape tracking techniques to solve each challenge:\n",
        "- **Challenge 1**: Basic `print()` statements to trace shapes\n",
        "- **Challenge 2**: Build a reusable helper function for cleaner tracking\n",
        "- **Challenge 3**: Comparative tracking to reveal batch-dependent behavior\n",
        "\n",
        "Each challenge requires you to: (1) add shape tracking, (2) identify the mismatch, and (3) fix the model's `__init__`/`forward()` method.\n",
        "\n",
        "Let's dive into the challenges!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 1 - Feature expansion gone wrong\n",
        "\n",
        "The HR team wants to improve predictions by adding two new job satisfaction features to the model. The data science team updated the input layer to accept 12 features instead of 10, but something else broke in the process..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate the feature expansion by adding 2 random features\n",
        "extra_features = torch.randn(X.shape[0], 2)\n",
        "X_expanded = torch.cat([X, extra_features], dim=1)  # Now 12 features\n",
        "\n",
        "print(f\"Original features: {X.shape}\")\n",
        "print(f\"Expanded features: {X_expanded.shape}\")\n",
        "print(f\"✓ Added 2 new job satisfaction metrics\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part A: Run the model, and observe the error\n",
        "\n",
        "Let's try to run the model and see what error we get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrokenExpandedMLP(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(BrokenExpandedMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(12, 20)\n",
        "        self.layer2 = nn.Linear(10, 5)\n",
        "        self.layer3 = nn.Linear(5, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "broken_model = BrokenExpandedMLP()\n",
        "print(\"Model with expanded input:\")\n",
        "print(broken_model)\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to run the model\n",
        "sample_batch = X_expanded[:5]\n",
        "\n",
        "print(f\"Input shape: {sample_batch.shape}\")\n",
        "print(\"\\nAttempting forward pass...\\n\")\n",
        "\n",
        "try:\n",
        "    output = broken_model(sample_batch)\n",
        "    print(f\"✓ Success! Output shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"✖ RuntimeError occurred!\")\n",
        "    print(f\"\\nError message: {e}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Understanding the error**: The error mentions matrix multiplication failure, but doesn't clearly indicate which layer or why. Time to add shape tracking."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part B: Add tensor shape tracking, and run again to debug\n",
        "\n",
        "Add `print()` statements to track tensor shapes at each step of the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrokenAttritionMLPWithTracking(nn.Module):\n",
        "    \"\"\"\n",
        "    Same broken model, but with shape tracking to debug the issue.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(BrokenAttritionMLPWithTracking, self).__init__()\n",
        "        self.layer1 = nn.Linear(12, 20)\n",
        "        self.layer2 = nn.Linear(10, 5)\n",
        "        self.layer3 = nn.Linear(5, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # TODO: Add print statements to track shapes\n",
        "        # Hint: Use print(f\"{Description}: {shape}\") at strategic points\n",
        "        # The description should describe what stage the tensor is at when you print its shape\n",
        "        # Reference: https://docs.pytorch.org/docs/stable/generated/torch.Tensor.shape.html\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = self.layer3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "# Instantiate model with tracking\n",
        "tracked_model = BrokenAttritionMLPWithTracking()\n",
        "print(\"Model with shape tracking created!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run with tracking\n",
        "print(\"Running forward pass WITH shape tracking:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    output = tracked_model(sample_batch)\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\n✓ Success! Output: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✖ Error still occurs, but now we can see exactly WHERE!\")\n",
        "    print(f\"\\nError: {e}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reading the tracking output**: Notice where the print statements stop. The last shape that successfully printed tells you exactly where the error occurs. Compare that shape to what the next layer expects (you can see this in the `__init__` method or in the error message's matrix dimensions)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part C: Fix the model, and run again\n",
        "\n",
        "Time to define the corrected model with properly aligned dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FixedExpandedMLP(nn.Module):\n",
        "    # TODO: Define the correct model with fixed dimensions\n",
        "    # Hint: You can copy-paste from BrokenAttritionMLPWithTracking, changing only what's needed\n",
        "    \n",
        "    # Add your code here\n",
        "\n",
        "fixed_model_1 = FixedExpandedMLP()\n",
        "print(\"Fixed model created!\\n\")\n",
        "print(fixed_model_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the fixed model\n",
        "print(\"Testing the fixed model:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    output = fixed_model_1(sample_batch)\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✓ SUCCESS! The model runs without errors.\")\n",
        "    print(f\"\\nOutput shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✖ Still broken. Review your fix and try again.\")\n",
        "    print(f\"\\nError: {e}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Verification success**: The shapes should now flow smoothly through every layer. Each transformation produces exactly what the next layer expects, and the model processes all 5 employees in parallel without issues."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TODO: Analysis question\n",
        "\n",
        "**Question:** Based on the shape tracking you added, explain why activation functions like ReLU don't cause shape mismatches, while Linear layers can. What's fundamentally different about how these two types of operations work?\n",
        "\n",
        "_Write your answer here:_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2: Deeper network, new problems\n",
        "\n",
        "To capture more complex patterns in attrition risk, the team decided to add an extra hidden layer, creating a deeper 4-layer architecture. The model compiles but crashes during the forward pass..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use original 10-feature dataset for this challenge\n",
        "sample_batch = X[:5]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part A: Run the model, and observe the error\n",
        "\n",
        "Let's try to run the model and see what error we get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrokenDeeperMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BrokenDeeperMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 30)\n",
        "        self.layer2 = nn.Linear(30, 15)\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "        self.layer4 = nn.Linear(10, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer4(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "broken_deeper = BrokenDeeperMLP()\n",
        "print(\"Deeper model created:\")\n",
        "print(broken_deeper)\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to run the model\n",
        "print(f\"Input shape: {sample_batch.shape}\")\n",
        "print(\"\\nAttempting forward pass...\\n\")\n",
        "\n",
        "try:\n",
        "    output = broken_deeper(sample_batch)\n",
        "    print(f\"✓ Success! Output shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"✖ RuntimeError occurred!\")\n",
        "    print(f\"\\nError message: {e}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **More layers, more places to break**: In deeper networks, simple print statements can become cluttered. Time to build a reusable debugging tool."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part B: Add tensor shape tracking, and run again to debug\n",
        "\n",
        "Instead of plain `print()` statements, build a reusable helper function that formats shape information clearly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create a helper function for formatted shape tracking\n",
        "# Hint: Use f-strings to format output as: \"name → shape\"\n",
        "# Format the name field to be 30 characters wide and shape to be 20 characters.\n",
        "# Reference: https://docs.python.org/3/tutorial/inputoutput.html#formatted-string-literals\n",
        "\n",
        "def print_shape_with_arrow(name, tensor):\n",
        "    \"\"\"\n",
        "    Helper function to print tensor shapes in a clean, readable format.\n",
        "    \n",
        "    Args:\n",
        "        name: Description of the operation/layer\n",
        "        tensor: The tensor whose shape we want to display\n",
        "    \"\"\"\n",
        "    # Add your code here\n",
        "\n",
        "# Test the helper function\n",
        "test_tensor = torch.randn(5, 10)\n",
        "print(\"\\nTesting the helper function:\")\n",
        "print(\"=\"*60)\n",
        "print_shape_with_arrow(\"Test input\", test_tensor)\n",
        "print(\"=\"*60)\n",
        "print(\"\\n✓ Helper function ready!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrokenDeeperMLPWithTracking(nn.Module):\n",
        "    \"\"\"\n",
        "    Same broken model, now using the helper function for tracking.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(BrokenDeeperMLPWithTracking, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 30)\n",
        "        self.layer2 = nn.Linear(30, 15)\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "        self.layer4 = nn.Linear(10, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # TODO: Use your helper function to track shapes at each step\n",
        "        # Hint: Call print_shape_with_arrow(description, tensor) throughout\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = self.layer3(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "tracked_deeper = BrokenDeeperMLPWithTracking()\n",
        "print(\"Model with enhanced tracking created!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run with enhanced tracking\n",
        "print(\"Running forward pass with FORMATTED shape tracking:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    output = tracked_deeper(sample_batch)\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\n✓ Success! Output: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nError: {e}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reading the formatted output**: The helper function makes it easy to scan through the shape flow. Notice where the prints stop - that's your clue. Check the unprinted layer's definition in `__init__` to identify the mismatch.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part C: Fix the model, and run again\n",
        "\n",
        "Time to define the corrected model with properly aligned dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FixedDeeperMLP(nn.Module):\n",
        "    # TODO: Define the correct model with fixed dimensions\n",
        "    # Hint: You can copy-paste from BrokenDeeperMLPWithTracking, changing only what's needed\n",
        "    \n",
        "    # Add your code here\n",
        "\n",
        "fixed_model_2 = FixedDeeperMLP()\n",
        "print(\"Fixed deeper model created!\\n\")\n",
        "print(fixed_model_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the fixed model\n",
        "print(\"Testing the fixed deeper model:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    output = fixed_model_2(sample_batch)\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✓ SUCCESS! The deeper model now runs without errors.\")\n",
        "    print(f\"\\nOutput shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n✖ Still broken. Review the layer dimensions.\")\n",
        "    print(f\"\\nError: {e}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Verification success**: The dimension chain should now be consistent: `10 → 30 → 15 → 10 → 1`. Your helper function made debugging and identifying the right fix much cleaner than manual inspection."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TODO: Analysis question\n",
        "\n",
        "**Question:** The error message said \"mat1 and mat2 shapes cannot be multiplied (5x15 and 20x10)\". You could technically figure out the broken layer by examining the `__init__()` method and mentally tracing which layer outputs 15 features and which expects 20. Why is adding shape tracking still more efficient than this mental tracing approach, especially as networks get deeper?\n",
        "\n",
        "_Write your answer here:_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3: The batch size 1 mystery\n",
        "\n",
        "The model has been updated with normalization to improve convergence. It passes all training tests (batch size 32), but crashes in production when processing single employees. This is a subtle bug that only appears with certain batch sizes..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use original 10-feature dataset for this challenge\n",
        "sample_batch = X[:32]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part A: Run the model, and observe the error\n",
        "\n",
        "Let's try to run the model and see what error we get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrokenBatchDependentMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BrokenBatchDependentMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 20)\n",
        "        self.layer2 = nn.Linear(20, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = x.reshape(32, 1, -1)  # (batch, 20) → (batch, 1, 20)\n",
        "        x = x.mean(dim=1)  # Average across dim 1: (batch, 1, 20) → (batch, 20)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "broken_batch = BrokenBatchDependentMLP()\n",
        "print(\"Batch-dependent model created:\")\n",
        "print(broken_batch)\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with batch size 32 (training scenario)\n",
        "print(\"Testing with training batch size:\")\n",
        "\n",
        "try:\n",
        "    output = broken_batch(sample_batch)\n",
        "    print(f\"✓ Works! Output shape: {output.shape}\\n\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"✖ Error: {e}\\n\")\n",
        "\n",
        "# Test with batch size 1 (production scenario)\n",
        "print(\"Testing with batch size 1 (production):\")\n",
        "batch_1 = X[:1]\n",
        "\n",
        "try:\n",
        "    output = broken_batch(batch_1)\n",
        "    print(f\"✓ Works! Output shape: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"✖ Error: {e}\")\n",
        "    print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Batch-dependent behavior**: The model's behavior changes based on input size. This suggests an operation that treats dimensions differently depending on their values."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part B: Add tensor shape tracking, and run again to debug\n",
        "\n",
        "Run both batch sizes and compare outputs side-by-side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrokenBatchDependentMLPWithTracking(nn.Module):\n",
        "    \"\"\"\n",
        "    Same broken model with comparative tracking.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(BrokenBatchDependentMLPWithTracking, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 20)\n",
        "        self.layer2 = nn.Linear(20, 1)\n",
        "    \n",
        "    def forward(self, x, batch_label=\"\"):\n",
        "        # TODO: Add comparative tracking focused on the batch size\n",
        "        # Hint: Include the `batch_label` parameter in your print\n",
        "        # This lets you run the same model with different batch sizes and compare outputs side-by-side.\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        x = x.reshape(32, 1, -1)\n",
        "        x = x.mean(dim=1)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "tracked_batch = BrokenBatchDependentMLPWithTracking()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run both batch sizes with tracking\n",
        "print(\"Comparative shape tracking:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nBatch size 32:\")\n",
        "print(\"-\" * 40)\n",
        "try:\n",
        "    output = tracked_batch(sample_batch)\n",
        "    print(f\"  ✓ Success! Output: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"  ✖ Error: {e}\")\n",
        "\n",
        "print(\"\\nBatch size 1:\")\n",
        "print(\"-\" * 40)\n",
        "try:\n",
        "    output = tracked_batch(batch_1)\n",
        "    print(f\"  ✓ Success! Output: {output.shape}\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"  ✖ Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reading the comparative output**: Execution stops at the reshape operation when Batch=1. The error message shows `[32, 1, -1]`. Notice an unexpected `32` appearing in the reshape - does that number make sense for a batch of size 1?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Part C: Fix the model, and run again\n",
        "\n",
        "Time to define the corrected model with properly aligned dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FixedBatchDependentMLP(nn.Module):\n",
        "    # TODO: Define the correct model with fixed dimensions\n",
        "    # Hint: You can copy-paste from BatchDependentMLPWithTracking, changing only what's needed\n",
        "    \n",
        "    # Add your code here\n",
        "\n",
        "fixed_model_3 = FixedBatchDependentMLP()\n",
        "print(\"Fixed batch-independent model created!\\n\")\n",
        "print(fixed_model_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with multiple batch sizes\n",
        "print(\"Testing fixed model with different batch sizes:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for batch_size in [1, 5, 32]:\n",
        "    batch = X[:batch_size]\n",
        "    print(f\"\\nBatch size: {batch_size}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    try:\n",
        "        output = fixed_model_3(batch)\n",
        "        print(f\"  ✓ Success! Consistent output shape: {output.shape}\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"  ✖ Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\n✓ Model works correctly with all batch sizes!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TODO: Analysis question\n",
        "\n",
        "**Question:** Why is hardcoding values like batch size a dangerous habit in neural networks? Beyond `reshape()`, what other PyTorch operations might behave unexpectedly when dimensions are hardcoded or when certain dimensions equal 1?\n",
        "\n",
        "_Write your answer here:_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Test with different batch sizes\n",
        "\n",
        "A robust model should handle any batch size gracefully. Let's verify all three fixed models work across different scenarios, from single predictions to large batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test all three fixed models comprehensively\n",
        "test_batch_sizes = [1, 5, 32, 128]\n",
        "\n",
        "print(\"Comprehensive batch size testing across all three models:\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Model 1: Feature expansion fix\n",
        "print(\"\\nModel 1: Feature Expansion (12 features → 1 output)\")\n",
        "print(\"-\" * 70)\n",
        "for batch_size in test_batch_sizes:\n",
        "    batch = X_expanded[:batch_size]\n",
        "    \n",
        "    with torch.no_grad():  # No gradients needed for testing\n",
        "        # Run without printing intermediate shapes\n",
        "        output = fixed_model_1.layer3(torch.relu(fixed_model_1.layer2(\n",
        "                 torch.relu(fixed_model_1.layer1(batch)))))\n",
        "        output = torch.sigmoid(output)\n",
        "    \n",
        "    print(f\"  Batch={batch_size:3d} → Input: {str(batch.shape):15s} → Output: {str(output.shape):15s} ✓\")\n",
        "\n",
        "# Model 2: Deeper network fix\n",
        "print(\"\\nModel 2: Deeper Network (10 → 30 → 15 → 10 → 1)\")\n",
        "print(\"-\" * 70)\n",
        "for batch_size in test_batch_sizes:\n",
        "    batch = X[:batch_size]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = fixed_model_2.layer4(torch.relu(fixed_model_2.layer3(\n",
        "                 torch.relu(fixed_model_2.layer2(torch.relu(\n",
        "                 fixed_model_2.layer1(batch)))))))\n",
        "        output = torch.sigmoid(output)\n",
        "    \n",
        "    print(f\"  Batch={batch_size:3d} → Input: {str(batch.shape):15s} → Output: {str(output.shape):15s} ✓\")\n",
        "\n",
        "# Model 3: Batch-dependent bug fix\n",
        "print(\"\\nModel 3: Batch-Independent (no fixed dimensions)\")\n",
        "print(\"-\" * 70)\n",
        "for batch_size in test_batch_sizes:\n",
        "    batch = X[:batch_size]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = fixed_model_3.layer2(torch.relu(fixed_model_3.layer1(batch)))\n",
        "        output = torch.sigmoid(output)\n",
        "    \n",
        "    print(f\"  Batch={batch_size:3d} → Input: {str(batch.shape):15s} → Output: {str(output.shape):15s} ✓\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\\n✓ All three models work correctly across all batch sizes!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Production-ready models are batch-agnostic**: All three fixed models now produce consistent output patterns: `(batch, 1)`. The first dimension scales with input, the second stays constant. Testing across [1, 5, 32, 128] confirms there are no hidden batch-dependent bugs. This robustness—working correctly whether processing one example or hundreds—is essential for real-world deployment where batch sizes vary unpredictably."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TODO: Analysis question\n",
        "\n",
        "**Question:** Based on your experience debugging all three models, why is testing with batch size 1 especially important? What kinds of bugs only appear at this edge case?\n",
        "\n",
        "_Write your answer here:_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations! You've successfully debugged three different types of shape-related errors using progressively sophisticated tracking techniques.\n",
        "\n",
        "**What you've accomplished:**\n",
        "\n",
        "- [x] **Debugged a feature expansion mismatch** - Fixed incompatible layer sizes after adding new input features\n",
        "- [x] **Debugged a deeper network** - Identified misaligned dimensions in a 4-layer architecture\n",
        "- [x] **Debugged a batch-dependent operation** - Fixed a hardcoded reshape that only worked with one fixed batch size value\n",
        "- [x] **Built reusable debugging tools** - Created helper functions for cleaner shape tracking\n",
        "- [x] **Verified robustness** - Tested all fixes across multiple batch sizes (1, 5, 32, 128)\n",
        "\n",
        "**Critical insights:**\n",
        "\n",
        "- **Shape tracking is your primary debugging tool**: Whether simple prints or helper functions, inspecting shapes reveals exactly where dimensions fail to align\n",
        "- **Linear layers transform dimensions**: Matrix multiplication changes feature counts and requires strict alignment between consecutive layers\n",
        "- **Activation functions preserve dimensions**: Element-wise operations like ReLU never cause shape mismatches\n",
        "- **Some operations are batch-dependent**: Hardcoded dimensions in operations like `reshape()` create bugs that only manifest with specific batch sizes\n",
        "- **Batch size 1 is the critical edge case**: Many bugs only manifest when the batch dimension equals 1, making it essential for testing\n",
        "- **Progressive debugging techniques**: Start simple (basic prints), then build tools (helper functions), then analyze systematically (comparative tracking)\n",
        "\n",
        "Shape mismatch errors aren't mysteries: they're clear signals pointing to architectural inconsistencies. By adding targeted shape tracking (instead of logging everything), you turn opaque runtime failures into clear debugging steps, saving hours when building custom architectures or adapting models. When something breaks, you now know exactly how to trace and fix it.\n",
        "\n",
        "> **Next steps to explore**: Print statements work for models you can edit, but for pre-trained or cleaner workflows, PyTorch’s hooks, decorators, and context managers let you log shapes non-invasively—ideal for scaling from development to production."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "36371cb60c26e37b7d9a2ceed614c6abe3cd2e9c2c4d621fd25f98fd923082ac"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
